{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline + Late Penalty\n",
    "\n",
    "$\\textbf{Note:}$ It will take you quite some time to complete this project, therefore, we earnestly recommend that you start working as early as possible. You should read the specs carefully at least 2-3 times before you start coding.\n",
    "\n",
    "**Submission deadline for the Project is 20:59:59 (08:59:59 PM) on 25th Nov, 2020**<br>\n",
    "**LATE PENALTY: -10% on day-1, -20% on day-2 and -70% on day-3 (i.e., 0 mark after 3 days late)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for $\\textbf{COMP6714-Project}$. \n",
    "\n",
    "* You are required to complete your implementation for part-1 in a file `project_part1.py` provided along with this notebook. Please $\\textbf{DO NOT ALTER}$ the name of the file.\n",
    "\n",
    "* You are required to complete a report for part-2 in a file `project_part2.pdf`.\n",
    "\n",
    "* You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "* You can submit your implementation for **Project (Part-1)**  and a report for **Project (Part-2)** via submission system: http://kg.cse.unsw.edu.au/submit/ . We have already sent out the invitations for you to join the submission system. In case of problems please post your request @ Piazza.\n",
    "\n",
    "* For each question, we have provided you with detailed instructions along with question headings. In case of problems, you can post your query @ Piazza.\n",
    "\n",
    "* You are allowed to add other functions and/or import modules (you may have to for this project), but you are not allowed to define global variables. **Only functions are allowed** in `project_part1.py`\n",
    "\n",
    "* You should not import unnecessary and non-standard modules/libraries. Loading such libraries at test time will lead to errors and hence 0 mark for your project. If you are not sure, please ask @ Piazza. \n",
    "\n",
    "* We will provide immediate feedback on your submission. You can access your scores using the online submission portal on the same day. \n",
    "\n",
    "* For the **Final Evaluation**, we will be using a different dataset, so your final scores may vary.  \n",
    "\n",
    "* You are allowed to have a limited number of Feedback Attempts $\\textbf{(15 Attempts for each student)}$, we will use your **LAST** submission for Final Evaluation.\n",
    "\n",
    "### Allowed Libraries:\n",
    "\n",
    "You are required to write your implementation for the project (part-1) using `Python 3.6.5`. You are allowed to use any python `standard libraries`(https://docs.python.org/3.6/library/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One (80 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this project, you are required to implement WAND algorithm. We use the variant version in 2013 ADCS paper [Exploring the Magic of WAND] Algorithm 1 WAND processing. We will provide a inverted indexing model which in `Inv_Index.py` **Please do not change this file**.\n",
    "\n",
    "### Inputs:\n",
    "Input to InvertedIndex model is as follow:\n",
    "1. Documents ($D$) as a dictionary with $key:$ doc_id; $value:$ document text\n",
    "\n",
    "During query, your WAND algorithm are received as follows:\n",
    "1. **query_terms** as a list with $term:$ a string list\n",
    "* **top_k** as a Integer $:top\\_k \\ge 1$, the number of documents you need to return\n",
    "* **inverted_index** as a dictionary with $key:$ term; $value:$ posting list, each element in posting list is a tuple $(doc\\_id, w_{t,d})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example for Illustration \n",
    "\n",
    "Here, we provide a small toy example for illustration of Inverted Index: <br>\n",
    "Let the dictionary of documents ($D$) be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {1:'President Trump was on his way to new New York in New York City.',\n",
    "             2:'New York Times mentioned an interesting story about Trump.',\n",
    "             3:'I think it would be great if I can travel to New York this summer to see Trump.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the provided inverted indexing model to get the inverted index. We do not use any preprocessing method(e.g. remove punctuation, stemming, case folding) and only use simple `split` function in python to get terms for each document.<br>\n",
    "Thus, the term list of doc_id = 1 would be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['President', 'Trump', 'was', 'on', 'his', 'way', 'to', 'new', 'New', 'York', 'in', 'New', 'York', 'City.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calcuate normalized tf-idf as $w_{t,d}$, the formula would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large w_{t,d} = \\left(1 + \\ln\\left(1 + \\ln\\left(tf_{t,d}\\right)\\right)\\right) \\cdot \\left( 1 + \\ln\\left(\\frac{|d|}{1 + df_t}\\right) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use InvertedIndex(documents).get_inverted_index() to get inverted index:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inverted_index = InvertedIndex(documents).get_inverted_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverted_index of term $New$ for $D$ would be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'New': [(1, 1.0874167370157617), (2, 0.7123179275482191), (3, 0.7123179275482191)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the query_terms ($Q$) be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q = [\"President\",\"New\",\"York\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Format:\n",
    "Your output should be two elements:<br>\n",
    "`topk_result` a list of the form `(score, doc_id)`, where <br>\n",
    "   * score a **float**: corresponds to the sum of TF-IDF score among all the term based on the intersection of $Q$ and $D$.\n",
    "   * doc_id a **integer**: is document unique id.\n",
    "   * the list should be sorted by score in decrease order.<br>\n",
    "   \n",
    "`full_evaluation_count` a **integer**: the number of documents fully evaluated in WAND algorithm.<br>\n",
    "**If two documents have same score, we only remain smaller document id.**<br>\n",
    "\n",
    "**NB: During testing, we will round your document scores by using `round(score, 5)` to avoid precision issue. Please keep raw document scores in your outputs.**\n",
    "\n",
    "### Running Time:\n",
    "* On CSE machines, your implementation for WAND algorithm $\\textbf{SHOULD NOT}$ take more than 120 seconds in our submit system.\n",
    "* In our testcases, the number of documents(with average around 400 terms) would not be greater than 3000, the number of terms in $Q$ would not be greater than 20, and k would not be greater than 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How we test implementation of part one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Inv_Index import InvertedIndex\n",
    "from project_part1 import WAND_Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'President Trump was on his way to new New York in New York City.',\n",
       " 2: 'New York Times mentioned an interesting story about Trump.',\n",
       " 3: 'I think it would be great if I can travel to New York this summer to see Trump.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './Data/sample_documents.pickle'\n",
    "documents = pickle.load(open(fname,\"rb\"))\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Construct and get inverted_index\n",
    "inverted_index = InvertedIndex(documents).get_inverted_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k result =  [(3.5802985821396875, 1), (1.4246358550964382, 2)]\n",
      "Evaluation Count =  3\n"
     ]
    }
   ],
   "source": [
    "## Test cases\n",
    "query_terms = [\"President\",\"New\",\"York\"]\n",
    "top_k = 2\n",
    "\n",
    "## 2. WAND algorithm...\n",
    "topk_result, full_evaluation_count = WAND_Algo(query_terms, top_k, inverted_index)\n",
    "\n",
    "print('Top-k result = ', topk_result)\n",
    "print('Evaluation Count = ', full_evaluation_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two (20 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Threshold $\\alpha$ is a very important parameter in WAND algorithm. If we can set a suitable value as initial threshold, we can reduce the number of fully evaluated documents. However, if we set a very high value, we may get wrong top-k result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: we only consider the WAND algorithm in lecture slides(i.e., Algorithm 1 described in the ADCS 2013 paper). <br>\n",
    "**With an important modification: Use the following 6 lines of code to replace Lines 28 to 34 of the ADCS2013 algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'img/modified_part.png' align = left width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This modification is only used in part two.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume that there is no two documents who achieve the same score for the query $Q$.\n",
    "2. Assume that we already had top-k answer for $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you need to complete a **report** `project_part2.pdf` answering the followoing questions:\n",
    "\n",
    "1. Find out the the upper bound ($\\alpha_{max}$) of threshold $\\alpha$ **such that** \n",
    "    1. $\\forall \\alpha < \\alpha_{max}$,  the algorithm (NB: the modified version of ADCS 2013 algorithm) will *always* return the correct top-k answers for $Q$; \n",
    "    2. $\\forall \\alpha \\geq \\alpha_{max}$, the algorithm *may* return the wrong top-k answers for $Q$ in some cases.\n",
    "2. Prove that your answer is correct in a rigorous way. \n",
    "\n",
    "Note: if we set $\\alpha = \\min \\{\\, score(D; Q) \\mid D \\in \\text{top-k}(Q) \\,\\}$, the algorithm will always return the correct top-k answers. However, we are sessking a higher value for $\\alpha$ here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Submission and Feedback\n",
    "\n",
    "For project submission, you are required to submit the following files via submission system: http://kg.cse.unsw.edu.au/submit/:\n",
    "\n",
    "1. A python file `project_part1.py`.\n",
    "2. A report `project_part2.pdf`.\n",
    "\n",
    "**Note:** Every student will be entitled to **15 Feedback Attempts** (use them wisely), we will use the last submission for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
