{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing by NLTK\n",
    "\n",
    "In this notebook, we will use `NLTK` to preprocess text documents. `NLTK` is a widely used library for Natural Language Processing. In addition to many built-in capabilities, it has interfaces to many corpus, other libraries, and a good online textbook/cookbook (http://www.nltk.org/book/). \n",
    "\n",
    "## Installing NLTK\n",
    "\n",
    "You need to\n",
    "\n",
    "* install NLTK: http://www.nltk.org/install.html\n",
    "* install NLTK data: http://www.nltk.org/data.html\n",
    "\n",
    "If everything is installed correctly, you should be able to run the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "*** Introductory Examples for the NLTK Book ***\nLoading text1, ..., text9 and sent1, ..., sent9\nType the name of the text or sentence to view it.\nType: &#39;texts()&#39; or &#39;sents()&#39; to list the materials.\ntext1: Moby Dick by Herman Melville 1851\ntext2: Sense and Sensibility by Jane Austen 1811\ntext3: The Book of Genesis\ntext4: Inaugural Address Corpus\ntext5: Chat Corpus\ntext6: Monty Python and the Holy Grail\ntext7: Wall Street Journal\ntext8: Personals Corpus\ntext9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;Text: Monty Python and the Holy Grail&gt;\n"
    }
   ],
   "source": [
    "doc = text6\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Displaying 10 of 10 matches:\nell , this is a temperate zone . ARTHUR : The swallow may fly south with the sun or the house marti\nhey could be carried . SOLDIER # 1 : What ? A swallow carrying a coconut ? ARTHUR : It could grip i\nIn order to maintain air - speed velocity , a swallow needs to beat its wings forty - three times e\nLDIER # 2 : It could be carried by an African swallow ! SOLDIER # 1 : Oh , yeah , an African swallo\nwallow ! SOLDIER # 1 : Oh , yeah , an African swallow maybe , but not a European swallow . That &#39; s\nan African swallow maybe , but not a European swallow . That &#39; s my point . SOLDIER # 2 : Oh , yeah\ning Arthur and Sir Bedevere , not more than a swallow &#39; s flight away , had discovered something . \nscovered something . Oh , that &#39; s an unladen swallow &#39; s flight , obviously . I mean , they were m\nhat is the air - speed velocity of an unladen swallow ? ARTHUR : What do you mean ? An African or E\nR : What do you mean ? An African or European swallow ? BRIDGEKEEPER : Huh ? I -- I don &#39; t know th\n"
    }
   ],
   "source": [
    "word = 'swallow'\n",
    "doc.concordance(word, width=100, lines=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Displaying 6 of 6 matches:\nNNIS : Man ! ARTHUR : Man . Sorry . What knight live in that castle over there ? DENNIS : I &#39; m thir\nste . Who lives in that castle ? WOMAN : No one live there . ARTHUR : Then who is your lord ? WOMAN \nhee ha ! Ha ha ha ha ... ARTHUR : Where does he live ? OLD MAN : ... Heh heh heh heh ... ARTHUR : Ol\neh heh heh ... ARTHUR : Old man , where does he live ? OLD MAN : ... Hee ha ha ha . He knows of a ca\neee - wom ! ARTHUR : Those who hear them seldom live to tell the tale ! HEAD KNIGHT : The Knights Wh\n ,-- HERBERT : Herbert . FATHER : &#39; Erbert . We live in a bloody swamp . We need all the land we can\n"
    }
   ],
   "source": [
    "word = 'live'\n",
    "doc.concordance(word, width=100, lines=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Displaying 1 of 1 matches:\no cruel that no man yet has fought with it and lived ! Bones of full fifty men lie strewn about its\n"
    }
   ],
   "source": [
    "word = 'lived'\n",
    "doc.concordance(word, width=100, lines=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Displaying 25 of 25 matches:\nI , Arthur , son of Uther Pendragon , from the castle of Camelot . King of the Britons , defeator of\nRTHUR : Man . Sorry . What knight live in that castle over there ? DENNIS : I &#39; m thirty - seven . A\n . I am Arthur , King of the Britons . Who &#39; s castle is that ? WOMAN : King of the who ? ARTHUR : T\nood people . I am in haste . Who lives in that castle ? WOMAN : No one live there . ARTHUR : Then wh\nse are my Knights of the Round Table . Who &#39; s castle is this ? FRENCH GUARD : This is the castle of\n s castle is this ? FRENCH GUARD : This is the castle of my master Guy de Loimbard . ARTHUR : Go and\nill not show us the Grail , we shall take your castle by force ! FRENCH GUARD : You don &#39; t frighten\n DIRECTOR : Action ! HISTORIAN : Defeat at the castle seems to have utterly disheartened King Arthur\nT : Welcome gentle Sir Knight . Welcome to the Castle Anthrax . GALAHAD : The Castle Anthrax ? ZOOT \n Welcome to the Castle Anthrax . GALAHAD : The Castle Anthrax ? ZOOT : Yes . Oh , it &#39; s not a very \nnd nineteen - and - a - half , cut off in this castle with no one to protect us . Oooh . It is a lon\nseek the Grail ! I have seen it , here in this castle ! DINGO : Oh no . Oh , no ! Bad , bad Zoot ! G\nn , and she must pay the penalty . And here in Castle Anthrax , we have but one punishment for setti\nswamp . Other kings said I was daft to build a castle on a swamp , but I built it all the same , jus\n what you &#39; re gonna get , lad : the strongest castle in these islands . HERBERT : But I don &#39; t wan\nnd rescue me . I am in the Tall Tower of Swamp Castle .&#39; At last ! A call ! A cry of distress ! This\nhen . Shall I , sir ? Yeah SCENE 16 : [ inside castle ] PRINCESS LUCKY and GIRLS : [ giggle giggle g\nand GIRLS : [ giggle giggle giggle ] [ outside castle ] GUEST : &#39; Morning ! SENTRY # 1 : &#39; Morning .\night of King Arthur , sir . FATHER : Very nice castle , Camelot . Uh , very good pig country ... LAU\n pure of spirit may find the Holy Grail in the Castle of uuggggggh &#39;. ARTHUR : What ? MAYNARD : &#39;...\nuggggggh &#39;. ARTHUR : What ? MAYNARD : &#39;... the Castle of uuggggggh &#39;. BEDEVERE : What is that ? MAYN\ninging stops ] [ ethereal music ] ARTHUR : The Castle Aaagh . Our quest is at an end ! God be praise\n of Camelot , to open the doors of this sacred castle , to which God Himself has guided us ! FRENCH \nf the Lord , we demand entrance to this sacred castle ! FRENCH GUARD : No chance , English bed - wet\nyou do not open this door , we shall take this castle by force ! [ splat ] In the name of God and th\n"
    }
   ],
   "source": [
    "word = 'CASTLE' \n",
    "doc.concordance(word, width=100, lines=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own `text` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;Text: To be or not to BE ? That...&gt;"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "from nltk import word_tokenize # sentence => words\n",
    "from nltk import sent_tokenize # document => sentences\n",
    "\n",
    "#str1 = \"to be or not to BE? That's a question. \"\n",
    "str1 = \"To be or not to BE?\\n That's a question. \"\n",
    "\n",
    "tokens = word_tokenize(str1)\n",
    "doc2 = Text(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the statistics\n",
    "\n",
    "* Document length\n",
    "* Vocalbury size\n",
    "* tf(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "# of tokens = 16967\n# of unique tokens = 2166\n"
    }
   ],
   "source": [
    "print('# of tokens = {}'.format(len(doc)))\n",
    "print('# of unique tokens = {}'.format(len(set(doc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;Text: To be or not to BE ? That...&gt;\n# of tokens = 12\n# of unique tokens = 12\n[&quot;&#39;s&quot;, &#39;.&#39;, &#39;?&#39;, &#39;BE&#39;, &#39;That&#39;, &#39;To&#39;, &#39;a&#39;, &#39;be&#39;, &#39;not&#39;, &#39;or&#39;, &#39;question&#39;, &#39;to&#39;]\nDisplaying 2 of 2 matches:\nTo be or not to BE ? That &#39;s a question .\nTo be or not to BE ? That &#39;s a question .\n"
    }
   ],
   "source": [
    "print(doc2)\n",
    "print('# of tokens = {}'.format(len(doc2)))\n",
    "print('# of unique tokens = {}'.format(len(set(doc2))))\n",
    "print(sorted(set(doc2)))\n",
    "doc2.concordance('be', width=100, lines=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n1\n1\n1\n0\n"
    }
   ],
   "source": [
    "print(doc2.count('to'))\n",
    "print(doc2.count('To'))\n",
    "print(doc2.count('be'))\n",
    "print(doc2.count('BE'))\n",
    "print(doc2.count('bE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4\n"
    }
   ],
   "source": [
    "occ = doc2.index('to')\n",
    "print(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;be&#39;, &#39;or&#39;, &#39;not&#39;, &#39;to&#39;, &#39;BE&#39;, &#39;?&#39;, &#39;That&#39;]"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "half_window = 3\n",
    "doc2[occ - half_window : occ + half_window +1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(&#39;:&#39;, 1197),\n (&#39;.&#39;, 816),\n (&#39;!&#39;, 801),\n (&#39;,&#39;, 731),\n (&quot;&#39;&quot;, 421),\n (&#39;[&#39;, 319),\n (&#39;]&#39;, 312),\n (&#39;the&#39;, 299),\n (&#39;I&#39;, 255),\n (&#39;ARTHUR&#39;, 225),\n (&#39;?&#39;, 207),\n (&#39;you&#39;, 204),\n (&#39;a&#39;, 188),\n (&#39;of&#39;, 158),\n (&#39;--&#39;, 148),\n (&#39;to&#39;, 144),\n (&#39;s&#39;, 141),\n (&#39;and&#39;, 135),\n (&#39;#&#39;, 127),\n (&#39;...&#39;, 118)]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "fd = FreqDist(doc)\n",
    "fd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[299, 5, 10]\n"
    }
   ],
   "source": [
    "words = ['the', 'knight', 'swallow']\n",
    "print( [fd[word] for word in words] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations and n-grams\n",
    "\n",
    "Collocations are good for getting a quick glimpse of what a text is about. `Collocations(num = VAL)` returns multi-word expressions that commonly co-occur. Notice that is not necessarily related to the frequency of the words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "BLACK KNIGHT; clop clop; HEAD KNIGHT; mumble mumble; Holy Grail;\nsqueak squeak; FRENCH GUARD; saw saw; Sir Robin; Run away\n"
    }
   ],
   "source": [
    "doc.collocations(num=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nltk.ngrams(text, n)` returns a *generator* of all n-grams in `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(&#39;SCENE&#39;, &#39;1&#39;, &#39;:&#39;), (&#39;1&#39;, &#39;:&#39;, &#39;[&#39;), (&#39;:&#39;, &#39;[&#39;, &#39;wind&#39;), (&#39;[&#39;, &#39;wind&#39;, &#39;]&#39;), (&#39;wind&#39;, &#39;]&#39;, &#39;[&#39;), (&#39;]&#39;, &#39;[&#39;, &#39;clop&#39;), (&#39;[&#39;, &#39;clop&#39;, &#39;clop&#39;), (&#39;clop&#39;, &#39;clop&#39;, &#39;clop&#39;), (&#39;clop&#39;, &#39;clop&#39;, &#39;]&#39;), (&#39;clop&#39;, &#39;]&#39;, &#39;KING&#39;)]\n"
    }
   ],
   "source": [
    "print(list(nltk.ngrams(doc, 3))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stopwords and Regular Expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16967\n2166\n13288\n2034\n"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "print(len(text6))\n",
    "print(len(set(text6)))\n",
    "new_text6 = [w for w in text6 if w not in stopwords]\n",
    "print(len(new_text6))\n",
    "print(len(set(new_text6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3\n[&#39;able&#39;, &#39;able&#39;, &#39;absolutely&#39;]\n"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "newer_text6 = [w for w in new_text6 if re.search('^ab',w)]\n",
    "print(len(newer_text6))\n",
    "print(newer_text6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Lemmatization\n",
    "\n",
    "In the following, we demonstrate \n",
    "* sentence segmentation\n",
    "* tokenizaiton \n",
    "* normalization\n",
    "* stemming\n",
    "* lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "To be or not to BE ? That &#39;s a question .\n"
    }
   ],
   "source": [
    "raw = \" \".join(list(doc2))\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;To be or not to BE ?&#39;, &quot;That &#39;s a question .&quot;]"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "sentences = sent_tokenize(raw)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;To&#39;, &#39;be&#39;, &#39;or&#39;, &#39;not&#39;, &#39;to&#39;, &#39;BE&#39;, &#39;?&#39;, &#39;That&#39;, &quot;&#39;s&quot;, &#39;a&#39;, &#39;question&#39;, &#39;.&#39;]"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;to&#39;, &#39;be&#39;, &#39;or&#39;, &#39;not&#39;, &#39;to&#39;, &#39;be&#39;, &#39;?&#39;, &#39;that&#39;, &quot;&#39;s&quot;, &#39;a&#39;, &#39;question&#39;, &#39;.&#39;]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "lc_tokens = [tk.lower() for tk in tokens]\n",
    "lc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;To&#39;, &#39;be&#39;, &#39;or&#39;, &#39;not&#39;, &#39;to&#39;, &#39;BE&#39;, &#39;?&#39;, &#39;that&#39;, &quot;&#39;s&quot;, &#39;a&#39;, &#39;question&#39;, &#39;.&#39;]"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "stemmed_tokens = [porter.stem(tk) for tk in tokens]\n",
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "corpu   linguist   propos   that   reliabl   languag   analysi   is   more   feasibl   with   corpora   collect   in   the   field   ,   in   their   natur   context   ,   and   with   minim   experimental-interfer   .\n"
    }
   ],
   "source": [
    "raw1 = 'Corpus linguistics proposes that reliable language analysis is more feasible with corpora collected in the field, in their natural contexts, and with minimal experimental-interference.'\n",
    "tokens = nltk.word_tokenize(raw1)\n",
    "print(\"   \".join(stemmed_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tokenization algorithm is pretty smart in not splitting `experimental-interference` into two tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "corpu   linguist   propos   that   reliabl   languag   analysi   is   more   feasibl   with   corpora   collect   in   the   field   ,   in   their   natur   context   ,   and   with   minim   experimental-interfer   .\n"
    }
   ],
   "source": [
    "stemmed_tokens = [porter.stem(tk) for tk in tokens]\n",
    "print(\"   \".join(stemmed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Corpus   linguistics   proposes   that   reliable   language   analysis   is   more   feasible   with   corpus   collected   in   the   field   ,   in   their   natural   context   ,   and   with   minimal   experimental-interference   .\n"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemmatized_tokens = [wnl.lemmatize(tk) for tk in tokens]\n",
    "print(\"   \".join(lemmatized_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably wonder by `proposes` above is not lemmatized to `propose`. This is because `lemmatize` method has a default optional parameter `pos = 'n'` (i.e., treating the `proposes` as a noun). If we specify the correct POS tag (`'v'` for verb), the output will be correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;propose&#39;"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "wnl.lemmatize('proposes', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;be&#39;"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "wnl.lemmatize('is', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(&#39;Corpus&#39;, &#39;NNP&#39;),\n (&#39;linguistics&#39;, &#39;NNS&#39;),\n (&#39;proposes&#39;, &#39;VBZ&#39;),\n (&#39;that&#39;, &#39;IN&#39;),\n (&#39;reliable&#39;, &#39;JJ&#39;),\n (&#39;language&#39;, &#39;NN&#39;),\n (&#39;analysis&#39;, &#39;NN&#39;),\n (&#39;is&#39;, &#39;VBZ&#39;),\n (&#39;more&#39;, &#39;RBR&#39;),\n (&#39;feasible&#39;, &#39;JJ&#39;),\n (&#39;with&#39;, &#39;IN&#39;),\n (&#39;corpora&#39;, &#39;NNS&#39;),\n (&#39;collected&#39;, &#39;VBN&#39;),\n (&#39;in&#39;, &#39;IN&#39;),\n (&#39;the&#39;, &#39;DT&#39;),\n (&#39;field&#39;, &#39;NN&#39;),\n (&#39;,&#39;, &#39;,&#39;),\n (&#39;in&#39;, &#39;IN&#39;),\n (&#39;their&#39;, &#39;PRP$&#39;),\n (&#39;natural&#39;, &#39;JJ&#39;),\n (&#39;contexts&#39;, &#39;NN&#39;),\n (&#39;,&#39;, &#39;,&#39;),\n (&#39;and&#39;, &#39;CC&#39;),\n (&#39;with&#39;, &#39;IN&#39;),\n (&#39;minimal&#39;, &#39;JJ&#39;),\n (&#39;experimental-interference&#39;, &#39;NN&#39;),\n (&#39;.&#39;, &#39;.&#39;)]"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Write a function that lemmatizes all words in a sentence by considering their POS tags. \n",
    " \n",
    "Wordnet only accepts the following POS tag: (from the source: http://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html)\n",
    "`ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'`\n",
    "\n",
    "You can use `nltk.pos_tag(tokens)` to obtain POS tags for the input token list. \n",
    "\n",
    "Your output should look like this (the tabular output is just showing the additional debugging info)\n",
    "\n",
    "```\n",
    "% proper_lemmatize_sentence(raw1, True)\n",
    "\n",
    "\n",
    "                       token/POS           lemmatized_token\n",
    "0                     Corpus/NNP                     Corpus\n",
    "1                linguistics/NNS                linguistics\n",
    "2                   proposes/VBZ                    propose\n",
    "3                        that/IN                       that\n",
    "4                    reliable/JJ                   reliable\n",
    "5                    language/NN                   language\n",
    "6                    analysis/NN                   analysis\n",
    "7                         is/VBZ                         be\n",
    "8                       more/RBR                       more\n",
    "9                    feasible/JJ                   feasible\n",
    "10                       with/IN                       with\n",
    "11                   corpora/NNS                     corpus\n",
    "12                 collected/VBN                    collect\n",
    "13                         in/IN                         in\n",
    "14                        the/DT                        the\n",
    "15                      field/NN                      field\n",
    "16                           ,/,                          ,\n",
    "17                         in/IN                         in\n",
    "18                    their/PRP$                      their\n",
    "19                    natural/JJ                    natural\n",
    "20                   contexts/NN                    context\n",
    "21                           ,/,                          ,\n",
    "22                        and/CC                        and\n",
    "23                       with/IN                       with\n",
    "24                    minimal/JJ                    minimal\n",
    "25  experimental-interference/NN  experimental-interference\n",
    "26                           ./.                          .\n",
    "\n",
    "['Corpus',\n",
    " 'linguistics',\n",
    " 'propose',\n",
    " 'that',\n",
    " 'reliable',\n",
    " 'language',\n",
    " 'analysis',\n",
    " 'be',\n",
    " 'more',\n",
    " 'feasible',\n",
    " 'with',\n",
    " 'corpus',\n",
    " 'collect',\n",
    " 'in',\n",
    " 'the',\n",
    " 'field',\n",
    " ',',\n",
    " 'in',\n",
    " 'their',\n",
    " 'natural',\n",
    " 'context',\n",
    " ',',\n",
    " 'and',\n",
    " 'with',\n",
    " 'minimal',\n",
    " 'experimental-interference',\n",
    " '.']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proper_lemmatize_sentence(rawl):\n",
    "    r = []\n",
    "    for i, j in nltk.pos_tag(tokens):\n",
    "        if 'VB' in j:\n",
    "            r.append(wnl.lemmatize(i, 'v'))\n",
    "            continue\n",
    "        r.append(wnl.lemmatize(i))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;Corpus&#39;,\n &#39;linguistics&#39;,\n &#39;propose&#39;,\n &#39;that&#39;,\n &#39;reliable&#39;,\n &#39;language&#39;,\n &#39;analysis&#39;,\n &#39;be&#39;,\n &#39;more&#39;,\n &#39;feasible&#39;,\n &#39;with&#39;,\n &#39;corpus&#39;,\n &#39;collect&#39;,\n &#39;in&#39;,\n &#39;the&#39;,\n &#39;field&#39;,\n &#39;,&#39;,\n &#39;in&#39;,\n &#39;their&#39;,\n &#39;natural&#39;,\n &#39;context&#39;,\n &#39;,&#39;,\n &#39;and&#39;,\n &#39;with&#39;,\n &#39;minimal&#39;,\n &#39;experimental-interference&#39;,\n &#39;.&#39;]"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "proper_lemmatize_sentence(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}